#!/usr/bin/env python3
"""
é‡æ–°è®¡ç®—å› æ–°é—»æºæƒé‡æ›´æ–°è€Œå—å½±å“çš„æ³¨æ„åŠ›ç‰¹å¾

æƒé‡æ›´æ–°åï¼Œä»¥ä¸‹å­—æ®µéœ€è¦é‡æ–°è®¡ç®—ï¼š
- weighted_attention
- bullish_attention  
- bearish_attention
- news_channel_score
- composite_attention_score
- composite_attention_zscore
- composite_attention_spike_flag
- detected_events

ä¸éœ€è¦æ›´æ–°çš„å­—æ®µï¼ˆå¤–éƒ¨æ•°æ®æºï¼‰ï¼š
- google_trend_* (Google Trends æ•°æ®)
- twitter_volume_* (Twitter æ•°æ®)
- news_count (çº¯è®¡æ•°)
- attention_score (ä»…åŸºäº news_count)
"""

import argparse
import sys
from datetime import datetime, timezone
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sqlalchemy import create_engine, func
from sqlalchemy.orm import sessionmaker
from src.config.settings import DATABASE_URL
from src.database.models import Symbol, AttentionFeature, News
from src.features.calculators import calculate_composite_attention
from src.features.event_detectors import detect_events_per_row
from src.data.db_storage import get_db
import pandas as pd


def get_symbols_to_update(session, symbols_filter=None):
    """è·å–éœ€è¦æ›´æ–°çš„ symbols"""
    query = session.query(Symbol).filter(Symbol.is_active == True)
    if symbols_filter:
        query = query.filter(Symbol.symbol.in_(symbols_filter))
    return [s.symbol for s in query.all()]


def recompute_features_for_symbol(symbol: str, timeframe: str = '1d', dry_run: bool = False):
    """é‡æ–°è®¡ç®—å•ä¸ª symbol çš„æ³¨æ„åŠ›ç‰¹å¾"""
    
    print(f"\n{'[DRY RUN] ' if dry_run else ''}å¤„ç† {symbol} ({timeframe})...")
    
    db = get_db()
    engine = create_engine(DATABASE_URL)
    Session = sessionmaker(bind=engine)
    session = Session()
    
    # æ ‡å‡†åŒ– timeframe æ ¼å¼
    # æ•°æ®åº“å­˜å‚¨: 'D', '4H'
    # API æŸ¥è¯¢: '1d', '4h'
    freq_map = {'1d': 'D', '4h': '4H', 'D': 'D', '4H': '4H'}
    freq_for_calc = freq_map.get(timeframe, 'D')  # ç”¨äº calculate_composite_attention
    freq_for_db = freq_for_calc  # æ•°æ®åº“ä¹Ÿä½¿ç”¨ 'D', '4H'
    
    # ä»·æ ¼æ•°æ®æŸ¥è¯¢éœ€è¦å°å†™æ ¼å¼
    timeframe_for_price = timeframe.lower()  # '1d' or '4h'
    
    try:
        # 1. è·å–è¯¥ symbol çš„ä»·æ ¼æ•°æ®
        symbol_obj = session.query(Symbol).filter(Symbol.symbol == symbol).first()
        if not symbol_obj:
            print(f"  âŒ æœªæ‰¾åˆ° symbol: {symbol}")
            return False
        
        price_data = db.get_prices(symbol, timeframe=timeframe_for_price)
        if price_data is None or price_data.empty:
            print(f"  âš ï¸  æ— ä»·æ ¼æ•°æ®")
            return False
        
        # 2. è·å–æ–°é—»æ•°æ®
        news_data = db.get_news(symbols=[symbol])
        if news_data is None or news_data.empty:
            print(f"  âš ï¸  æ— æ–°é—»æ•°æ®ï¼Œè·³è¿‡")
            return False
        
        # 3. è·å– Google Trends å’Œ Twitter æ•°æ®ï¼ˆè¿™äº›ä¸éœ€è¦é‡ç®—ï¼Œä½†è®¡ç®—æ—¶éœ€è¦ï¼‰
        google_trends = None
        twitter_volume = None
        
        # å°è¯•ä»ç°æœ‰ attention_features ä¸­æå– Google/Twitter æ•°æ®
        existing_features = session.query(AttentionFeature).filter(
            AttentionFeature.symbol_id == symbol_obj.id,
            AttentionFeature.timeframe == freq_for_db
        ).all()
        
        if existing_features:
            google_trends = pd.DataFrame([{
                'datetime': f.datetime,
                'google_trend_value': f.google_trend_value or 0.0
            } for f in existing_features])
            
            twitter_volume = pd.DataFrame([{
                'datetime': f.datetime,
                'twitter_volume': f.twitter_volume or 0.0
            } for f in existing_features])
        
        print(f"  ğŸ“Š æ–°é—»æ•°æ®: {len(news_data)} æ¡")
        print(f"  ğŸ’° ä»·æ ¼æ•°æ®: {len(price_data)} è¡Œ")
        print(f"  ğŸ” Google Trends: {len(google_trends) if google_trends is not None else 0} è¡Œ")
        print(f"  ğŸ¦ Twitter: {len(twitter_volume) if twitter_volume is not None else 0} è¡Œ")
        
        # 4. é‡æ–°è®¡ç®—æ³¨æ„åŠ›ç‰¹å¾
        result_df = calculate_composite_attention(
            symbol=symbol,
            price_df=price_data,
            news_df=news_data,
            google_trends_df=google_trends,
            twitter_volume_df=twitter_volume,
            freq=freq_for_calc
        )
        
        if result_df is None or result_df.empty:
            print(f"  âŒ è®¡ç®—å¤±è´¥")
            return False
        
        # 5. æ£€æµ‹äº‹ä»¶
        result_df = detect_events_per_row(result_df)
        
        # 6. æ›´æ–°æ•°æ®åº“
        if not dry_run:
            updated_count = 0
            for _, row in result_df.iterrows():
                record = {
                    'datetime': row['datetime'],
                    'timeframe': row['timeframe'],
                    'weighted_attention': row.get('weighted_attention', 0.0),
                    'bullish_attention': row.get('bullish_attention', 0.0),
                    'bearish_attention': row.get('bearish_attention', 0.0),
                    'news_channel_score': row.get('news_channel_score', 0.0),
                    'composite_attention_score': row.get('composite_attention_score', 0.0),
                    'composite_attention_zscore': row.get('composite_attention_zscore', 0.0),
                    'composite_attention_spike_flag': row.get('composite_attention_spike_flag', 0),
                    'detected_events': row.get('detected_events'),
                }
                
                # æŸ¥æ‰¾å¹¶æ›´æ–°ç°æœ‰è®°å½•
                existing = session.query(AttentionFeature).filter(
                    AttentionFeature.symbol_id == symbol_obj.id,
                    AttentionFeature.datetime == record['datetime'],
                    AttentionFeature.timeframe == freq_for_db
                ).first()
                
                if existing:
                    # åªæ›´æ–°å—å½±å“çš„å­—æ®µï¼Œä¿ç•™ Google/Twitter æ•°æ®
                    existing.weighted_attention = record['weighted_attention']
                    existing.bullish_attention = record['bullish_attention']
                    existing.bearish_attention = record['bearish_attention']
                    existing.news_channel_score = record['news_channel_score']
                    existing.composite_attention_score = record['composite_attention_score']
                    existing.composite_attention_zscore = record['composite_attention_zscore']
                    existing.composite_attention_spike_flag = record['composite_attention_spike_flag']
                    existing.detected_events = record['detected_events']
                    updated_count += 1
            
            session.commit()
            print(f"  âœ… å·²æ›´æ–° {updated_count} æ¡è®°å½•")
        else:
            print(f"  ğŸ” [DRY RUN] å°†æ›´æ–° {len(result_df)} æ¡è®°å½•")
            # æ˜¾ç¤ºå‰åå¯¹æ¯”ç¤ºä¾‹ï¼ˆæ˜¾ç¤ºæœ€è¿‘æœ‰æ•°æ®çš„è®°å½•ï¼‰
            if existing_features and len(existing_features) > 0:
                print("\n  ğŸ“Š æ ·æœ¬å¯¹æ¯”ï¼ˆæœ€è¿‘æœ‰æƒé‡æ•°æ®çš„5æ¡ï¼‰ï¼š")
                shown_count = 0
                for _, new_row in result_df.sort_values('datetime', ascending=False).iterrows():
                    old_feature = next((f for f in existing_features if f.datetime == new_row['datetime']), None)
                    if old_feature and old_feature.weighted_attention > 0:
                        shown_count += 1
                        print(f"\n    [{shown_count}] {new_row['datetime'].strftime('%Y-%m-%d')}:")
                        print(f"      weighted_attention:  {old_feature.weighted_attention:.4f} -> {new_row['weighted_attention']:.4f} "
                              f"({'+'if new_row['weighted_attention'] > old_feature.weighted_attention else ''}{(new_row['weighted_attention'] - old_feature.weighted_attention):.4f})")
                        print(f"      bullish_attention:   {old_feature.bullish_attention:.4f} -> {new_row['bullish_attention']:.4f} "
                              f"({'+'if new_row['bullish_attention'] > old_feature.bullish_attention else ''}{(new_row['bullish_attention'] - old_feature.bullish_attention):.4f})")
                        print(f"      bearish_attention:   {old_feature.bearish_attention:.4f} -> {new_row['bearish_attention']:.4f} "
                              f"({'+'if new_row['bearish_attention'] > old_feature.bearish_attention else ''}{(new_row['bearish_attention'] - old_feature.bearish_attention):.4f})")
                        print(f"      composite_score:     {old_feature.composite_attention_score:.4f} -> {new_row['composite_attention_score']:.4f} "
                              f"({'+'if new_row['composite_attention_score'] > old_feature.composite_attention_score else ''}{(new_row['composite_attention_score'] - old_feature.composite_attention_score):.4f})")
                        
                        if shown_count >= 5:
                            break
        
        return True
        
    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        session.rollback()
        return False
    finally:
        session.close()


def main():
    parser = argparse.ArgumentParser(
        description='é‡æ–°è®¡ç®—å› æƒé‡æ›´æ–°è€Œå—å½±å“çš„æ³¨æ„åŠ›ç‰¹å¾'
    )
    parser.add_argument(
        '--symbols',
        nargs='+',
        help='è¦æ›´æ–°çš„ symbolsï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼Œä¸æŒ‡å®šåˆ™æ›´æ–°æ‰€æœ‰æ´»è·ƒ symbols'
    )
    parser.add_argument(
        '--timeframe',
        default='1d',
        choices=['1d', '4h'],
        help='æ—¶é—´ç²’åº¦ï¼ˆé»˜è®¤: 1dï¼‰'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…æ›´æ–°æ•°æ®åº“'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("é‡æ–°è®¡ç®—æ³¨æ„åŠ›ç‰¹å¾ï¼ˆæƒé‡æ›´æ–°åï¼‰")
    print("=" * 60)
    
    if args.dry_run:
        print("âš ï¸  DRY RUN æ¨¡å¼ - ä¸ä¼šä¿®æ”¹æ•°æ®åº“")
    
    # è·å–è¦æ›´æ–°çš„ symbols
    engine = create_engine(DATABASE_URL)
    Session = sessionmaker(bind=engine)
    session = Session()
    
    symbols = get_symbols_to_update(session, args.symbols)
    session.close()
    
    if not symbols:
        print("âŒ æœªæ‰¾åˆ°è¦æ›´æ–°çš„ symbols")
        return 1
    
    print(f"\nå°†å¤„ç† {len(symbols)} ä¸ª symbols: {', '.join(symbols)}")
    print(f"æ—¶é—´ç²’åº¦: {args.timeframe}")
    
    if not args.dry_run:
        confirm = input("\nç¡®è®¤å¼€å§‹æ›´æ–°ï¼Ÿ(y/N): ")
        if confirm.lower() != 'y':
            print("å·²å–æ¶ˆ")
            return 0
    
    # å¤„ç†æ¯ä¸ª symbol
    success_count = 0
    fail_count = 0
    
    for symbol in symbols:
        if recompute_features_for_symbol(symbol, args.timeframe, args.dry_run):
            success_count += 1
        else:
            fail_count += 1
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("å¤„ç†å®Œæˆ")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±è´¥: {fail_count}")
    
    if args.dry_run:
        print("\nğŸ’¡ è¿™æ˜¯è¯•è¿è¡Œæ¨¡å¼ã€‚è¦å®é™…æ›´æ–°æ•°æ®åº“ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°")
    
    return 0 if fail_count == 0 else 1


if __name__ == '__main__':
    sys.exit(main())
